import os
import google.generativeai as genai
from supabase import create_client, Client
# PDF ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì œê±°: from pypdf import PdfReader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
import traceback # ì˜¤ë¥˜ ì¶”ì ì„ ìœ„í•´ ì¶”ê°€
from sentence_transformers import SentenceTransformer  # ì¶”ê°€: Sentence Transformer ì„í¬íŠ¸

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# --- ì„¤ì • ---
# Supabase ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥)
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_KEY") # ì„œë²„ í™˜ê²½ì—ì„œëŠ” service_role í‚¤ ì‚¬ìš© ê°€ëŠ¥
# Google AI ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥)
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")

# Supabase í…Œì´ë¸” ë° í•¨ìˆ˜ ì´ë¦„ ë³€ê²½
TABLE_NAME = "sentencetransformermdrules" # í…Œì´ë¸” ì´ë¦„ ë³€ê²½
MATCH_FUNCTION_NAME = "match_sentencetransformermdrules_documents" # ì˜¤ë¥˜ íŒíŠ¸ì— ë”°ë¼ í•¨ìˆ˜ ì´ë¦„ ìˆ˜ì •

# Supabase í…Œì´ë¸” ë° í•¨ìˆ˜ ì´ë¦„ ë³€ê²½
# TABLE_NAME = "mdrules" # í…Œì´ë¸” ì´ë¦„ ë³€ê²½
# MATCH_FUNCTION_NAME = "match_mdrules_documents" # ê²€ìƒ‰ í•¨ìˆ˜ ì´ë¦„ ë³€ê²½

# ì„ë² ë”© ëª¨ë¸ ì„¤ì • (all-mpnet-base-v2ëŠ” 768ì°¨ì› ë²¡í„°ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸)
SENTENCE_TRANSFORMER_MODEL = "all-mpnet-base-v2"  # ì°¨ì› ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ 768ì°¨ì› ëª¨ë¸ë¡œ ë³€ê²½
GENERATION_MODEL = "gemini-2.5-flash"#"gemini-2.5-flash-preview-05-20" #"gemini-2.5-pro-preview-06-05"

# LLM ìƒì„± ì„¤ì •
LLM_TEMPERATURE = 1.3  # ì°½ì˜ì„± ìˆ˜ì¤€ (0.0=ê²°ì •ì , 1.0=ë§¤ìš°ì°½ì˜ì )
LLM_TOP_P = 0.8        # í† í° ì„ íƒ ë‹¤ì–‘ì„±
LLM_TOP_K = 40         # í›„ë³´ í† í° ìˆ˜
LLM_MAX_TOKENS = 8192  # ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜

# --- ì´ˆê¸°í™” ---
try:
    # Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    print("Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")

    # Google AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (LLMìš©ìœ¼ë¡œë§Œ ì‚¬ìš©)
    genai.configure(api_key=GOOGLE_API_KEY)
    print(f"Google AI (LLM: {GENERATION_MODEL}) í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
    
    # Sentence Transformer ëª¨ë¸ ì´ˆê¸°í™”
    sentence_model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL)
    embed_dim = sentence_model.get_sentence_embedding_dimension()
    print(f"Sentence Transformer ëª¨ë¸ ({SENTENCE_TRANSFORMER_MODEL}) ì´ˆê¸°í™” ì„±ê³µ")
    print(f"ëª¨ë¸ ë²¡í„° ì°¨ì›: {embed_dim}")

except Exception as e:
    print(f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    print(traceback.format_exc()) # ìƒì„¸ ì˜¤ë¥˜ ì¶œë ¥
    exit()

# --- í•¨ìˆ˜ ì •ì˜ ---

def read_markdown_file(md_path: str) -> str:
    """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤."""
    try:
        # UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ ì½ê¸° (ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì— ì¼ë°˜ì )
        with open(md_path, 'r', encoding='utf-8') as f:
            text = f.read()
        print(f"'{md_path}'ì—ì„œ í…ìŠ¤íŠ¸ ì½ê¸° ì™„ë£Œ (ê¸¸ì´: {len(text)})")
        return text
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: íŒŒì¼ '{md_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return ""
    except Exception as e:
        print(f"ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì½ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(traceback.format_exc()) # ìƒì„¸ ì˜¤ë¥˜ ì¶œë ¥
        return ""

# split_text í•¨ìˆ˜ëŠ” ë³€ê²½ ì—†ìŒ (í…ìŠ¤íŠ¸ ë¶„í•  ë¡œì§ ë™ì¼)
def split_text(text: str, chunk_size: int = 1500, chunk_overlap: int = 400) -> list[str]:
    """í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ í¬ê¸°ì˜ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤."""
    try:
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            is_separator_regex=False, # Markdown íŠ¹ìˆ˜ ë¬¸ìë¥¼ ë¶„ë¦¬ìë¡œ ê°„ì£¼í•˜ì§€ ì•Šë„ë¡ False ìœ ì§€
        )
        chunks = text_splitter.split_text(text)
        # ë¹ˆ ì²­í¬ ì œê±° (íŒŒì¼ ì‹œì‘/ëì˜ ê³µë°± ë“±ìœ¼ë¡œ ì¸í•´ ë°œìƒ ê°€ëŠ¥)
        chunks = [chunk for chunk in chunks if chunk.strip()]
        print(f"í…ìŠ¤íŠ¸ë¥¼ {len(chunks)}ê°œì˜ ìœ íš¨í•œ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ")
        return chunks
    except Exception as e:
        print(f"í…ìŠ¤íŠ¸ ë¶„í•  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(traceback.format_exc()) # ìƒì„¸ ì˜¤ë¥˜ ì¶œë ¥
        return []

# get_embedding í•¨ìˆ˜ ë³€ê²½ (Sentence Transformer ì‚¬ìš©)
def get_embedding(text: str) -> list[float] | None:
    """ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ Sentence Transformerë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±í•©ë‹ˆë‹¤."""
    # ë§¤ìš° ì§§ì€ í…ìŠ¤íŠ¸ë‚˜ ê³µë°±ë§Œ ìˆëŠ” í…ìŠ¤íŠ¸ëŠ” ì„ë² ë”© ìš”ì²­í•˜ì§€ ì•ŠìŒ
    if not text or text.isspace():
        print("  ê²½ê³ : ë¹„ì–´ ìˆê±°ë‚˜ ê³µë°±ë§Œ ìˆëŠ” í…ìŠ¤íŠ¸ëŠ” ì„ë² ë”©ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    try:
        # Sentence Transformerë¡œ ì„ë² ë”© ìƒì„±
        embedding = sentence_model.encode(text)
        # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜ (Supabaseì— ì €ì¥ ê°€ëŠ¥í•œ í˜•íƒœ)
        return embedding.tolist()
    except Exception as e:
        error_message = f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        print(error_message)
        print(traceback.format_exc()) # ìƒì„¸ ì˜¤ë¥˜ ì¶œë ¥ì„ í™œì„±í™”
        return None

# store_chunks_in_supabase í•¨ìˆ˜ëŠ” í…Œì´ë¸” ì´ë¦„(TABLE_NAME) ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ë‚´ë¶€ ë¡œì§ ë³€ê²½ ë¶ˆí•„ìš”
def store_chunks_in_supabase(chunks: list[str]):
    """í…ìŠ¤íŠ¸ ì²­í¬ì™€ ì„ë² ë”©ì„ Supabaseì— ì €ì¥í•©ë‹ˆë‹¤."""
    print(f"ì´ {len(chunks)}ê°œì˜ ì²­í¬ë¥¼ Supabase '{TABLE_NAME}' í…Œì´ë¸”ì— ì €ì¥ ì‹œì‘...")
    stored_count = 0
    skipped_count = 0
    for i, chunk in enumerate(chunks):
        # ì²­í¬ ë‚´ìš© ì•ë’¤ ê³µë°± ì œê±°
        cleaned_chunk = chunk.strip()
        if not cleaned_chunk: # ê³µë°± ì œê±° í›„ ë‚´ìš©ì´ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€
            print(f"  ì²­í¬ {i+1}/{len(chunks)} ê±´ë„ˆëœ€ (ë‚´ìš© ì—†ìŒ).")
            skipped_count += 1
            continue

        embedding = get_embedding(cleaned_chunk) # ì •ì œëœ ì²­í¬ë¡œ ì„ë² ë”© ìƒì„±
        if embedding:
            # ì„ë² ë”© ì°¨ì› í™•ì¸
            print(f"  ì„ë² ë”© ì°¨ì›: {len(embedding)}")
            try:
                # í…Œì´ë¸” ì´ë¦„ ë³€ìˆ˜ ì‚¬ìš©
                data, count = supabase.table(TABLE_NAME).insert({
                    "content": cleaned_chunk, # ì •ì œëœ ì²­í¬ ì €ì¥
                    "embedding": embedding
                }).execute()
                # dataë‚˜ count ëŒ€ì‹  ì‹¤ì œ ì‘ë‹µ ìƒíƒœ í™•ì¸ì´ ë” ì •í™•í•  ìˆ˜ ìˆìŒ
                stored_count += 1
                print(f"  ì²­í¬ {i+1}/{len(chunks)} ì €ì¥ ì„±ê³µ.")
            except Exception as e:
                print(f"  ì²­í¬ {i+1}/{len(chunks)} ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print(traceback.format_exc()) # ìƒì„¸ ì˜¤ë¥˜ ì¶œë ¥
                skipped_count += 1
        else:
            print(f"  ì²­í¬ {i+1}/{len(chunks)} ì €ì¥ ì‹¤íŒ¨ (ì„ë² ë”© ìƒì„± ì‹¤íŒ¨).")
            skipped_count += 1

    print(f"ì´ {stored_count}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ, {skipped_count}ê°œ ê±´ë„ˆëœ€/ì‹¤íŒ¨.")


# find_similar_chunks í•¨ìˆ˜ ë³€ê²½ (Sentence Transformer ì‚¬ìš©)
def find_similar_chunks(query: str, match_count: int = 3, match_threshold: float = 0.7) -> list[tuple[float, str]]:
    """ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ Supabaseì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    try:
        # Sentence Transformerë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ ì„ë² ë”© ìƒì„±
        query_embedding = sentence_model.encode(query).tolist()
        print(f"ì¿¼ë¦¬ ì„ë² ë”© ì°¨ì›: {len(query_embedding)}")

        # ğŸš¨ NEW: íƒ€ì„ì•„ì›ƒ ì¶”ê°€
        import threading
        import time
        
        # íƒ€ì„ì•„ì›ƒì„ ìœ„í•œ ê²°ê³¼ ì €ì¥ ë³€ìˆ˜
        search_result = {"response": None, "error": None, "completed": False}
        
        def supabase_search_with_timeout():
            """íƒ€ì„ì•„ì›ƒì´ ìˆëŠ” Supabase ê²€ìƒ‰"""
            try:
                start_time = time.time()
                print(f"ğŸ” Supabase RPC í˜¸ì¶œ ì‹œì‘: {MATCH_FUNCTION_NAME}")
                
                # Supabase í•¨ìˆ˜ í˜¸ì¶œ (í•¨ìˆ˜ ì´ë¦„ ë³€ìˆ˜ ì‚¬ìš©)
                response = supabase.rpc(MATCH_FUNCTION_NAME, {
                    'query_embedding': query_embedding,
                    'match_threshold': match_threshold,
                    'match_count': match_count
                }).execute()
                
                end_time = time.time()
                search_result["response"] = response
                search_result["completed"] = True
                print(f"âœ… Supabase RPC ì‘ë‹µ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {end_time - start_time:.1f}ì´ˆ)")
                
            except Exception as e:
                search_result["error"] = str(e)
                search_result["completed"] = True
                print(f"âŒ Supabase RPC í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ Supabase ê²€ìƒ‰ ì‹¤í–‰
        search_thread = threading.Thread(target=supabase_search_with_timeout)
        search_thread.daemon = True
        search_thread.start()
        
        # íƒ€ì„ì•„ì›ƒ ëŒ€ê¸° (15ì´ˆ)
        timeout_seconds = 15
        wait_time = 0
        
        while wait_time < timeout_seconds and not search_result["completed"]:
            time.sleep(1)
            wait_time += 1
            
            # 3ì´ˆë§ˆë‹¤ ì§„í–‰ ìƒí™© ë¡œê¹…
            if wait_time % 3 == 0:
                print(f"â³ Supabase ê²€ìƒ‰ ëŒ€ê¸° ì¤‘... ({wait_time}/{timeout_seconds}ì´ˆ)")
        
        # íƒ€ì„ì•„ì›ƒ ì²´í¬
        if not search_result["completed"]:
            print(f"â° Supabase ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ ({timeout_seconds}ì´ˆ) - ë¹ˆ ê²°ê³¼ ë°˜í™˜")
            return []
        
        # ê²€ìƒ‰ ì˜¤ë¥˜ ì²´í¬
        if search_result["error"]:
            print(f"âŒ Supabase ê²€ìƒ‰ ì˜¤ë¥˜: {search_result['error']}")
            return []
        
        # ì •ìƒ ì‘ë‹µ ì²˜ë¦¬
        response = search_result["response"]
        if response and response.data:
            # (ìœ ì‚¬ë„ ì ìˆ˜, ë‚´ìš©) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
            similar_chunks = [(item.get('similarity', 0.0), item['content']) for item in response.data]
            print(f"'{query}'ì™€(ê³¼) ìœ ì‚¬í•œ ì²­í¬ {len(similar_chunks)}ê°œ ê²€ìƒ‰ ì™„ë£Œ (í…Œì´ë¸”: {TABLE_NAME}).")
            # for i in range(len(similar_chunks)):
            #     print(f"similar_chunks[{i}]: ", similar_chunks[i],"\n") # í…ŒìŠ¤íŠ¸ìš© : ì–´ë–¤ ì²­í¬ë“¤ì„ ê°€ì§€ê³  ì™”ëŠ”ê°€?
            return similar_chunks
        else:
            print(f"ìœ ì‚¬í•œ ì²­í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (í…Œì´ë¸”: {TABLE_NAME}, ì„ê³„ê°’: {match_threshold}).")
            return []
            
    except Exception as e:
        print(f"ìœ ì‚¬ì„± ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(traceback.format_exc()) # ìƒì„¸ ì˜¤ë¥˜ ì¶œë ¥
        return []

def generate_answer_without_rag(query, session_type="ê¸°íƒ€", character_context=""):
    """RAG ì—†ì´ ìˆœìˆ˜ LLMë§Œìœ¼ë¡œ ë‹µë³€ ìƒì„±"""
    try:
        # ì„¸ì…˜ ìœ í˜•ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì¡°ì •
        session_guidance = ""
        if session_type == "ìºë¦­í„°_ìƒì„±":
            session_guidance = """
ë‹¹ì‹ ì€ ì§€ê¸ˆ ìºë¦­í„° ìƒì„± ì„¸ì…˜ì— ìˆìŠµë‹ˆë‹¤. í”Œë ˆì´ì–´ê°€ ìºë¦­í„°ë¥¼ ë§Œë“œëŠ” ê²ƒì„ ë•ê³  ìˆìœ¼ë‹ˆ, 
ìºë¦­í„° ìƒì„±ì— í•„ìš”í•œ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”. ë§Œì•½ í”Œë ˆì´ì–´ê°€ ëœë¤ ìºë¦­í„°ë‚˜ ë¬´ì‘ìœ„ ìºë¦­í„°ë¥¼ ë§Œë“¤ì–´ë‹¬ë¼ê³  í•˜ë©´, 
ìºë¦­í„°ê°€ ìƒì„±ë  ê²ƒì´ë¼ê³  ì•ˆë‚´í•´ ì£¼ì„¸ìš”.
"""
        elif session_type == "ì‹œë‚˜ë¦¬ì˜¤_ìƒì„±":
            session_guidance = """
ë‹¹ì‹ ì€ ì§€ê¸ˆ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì„¸ì…˜ì— ìˆìŠµë‹ˆë‹¤. í¥ë¯¸ë¡œìš´ ëª¨í—˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“¤ê³  ìˆìœ¼ë‹ˆ,
í”Œë ˆì´ì–´ì˜ ì§ˆë¬¸ì— ë§ê²Œ ì´ì•¼ê¸°, ì¥ì†Œ, ë¹„ë°€, ë³´ë¬¼, NPC ë“±ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
"""
        elif session_type == "ëª¨í—˜_ì§„í–‰" or session_type == "ë˜ì „_íƒí—˜":
            session_guidance = """
ë‹¹ì‹ ì€ ì§€ê¸ˆ ëª¨í—˜/ë˜ì „ íƒí—˜ ì„¸ì…˜ì— ìˆìŠµë‹ˆë‹¤. ê²Œì„ë§ˆìŠ¤í„°ë¡œì„œ í”Œë ˆì´ì–´ì˜ í–‰ë™ì— ë°˜ì‘í•˜ê³ ,
ì£¼ë³€ í™˜ê²½ê³¼ ìƒí™©ì— ëŒ€í•œ ìƒìƒí•œ ì„¤ëª…ì„ ì œê³µí•˜ì„¸ìš”. ë„ì „ê³¼ ìœ„í—˜ì„ ê´€ë¦¬í•˜ê³  í”Œë ˆì´ì–´ê°€ ì„ íƒí•  ìˆ˜ ìˆëŠ” ì˜µì…˜ì„ ì œì‹œí•˜ì„¸ìš”.
"""
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (RAG ì—†ì´ ìˆœìˆ˜ LLM ìƒì„±)
        prompt = f"""
ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ê¸°ë°˜ TRPG(í…Œì´ë¸”í†± ë¡¤í”Œë ˆì‰ ê²Œì„)ì˜ ê²Œì„ë§ˆìŠ¤í„°ì…ë‹ˆë‹¤. 

## ì„¸ì…˜ ì •ë³´
í˜„ì¬ ì„¸ì…˜: {session_type}
{session_guidance}

## ìºë¦­í„° ì •ë³´
{character_context}

## ì‚¬ìš©ì ì§ˆë¬¸
"{query}"

## ì§€ì¹¨
1. ê²Œì„ë§ˆìŠ¤í„°ë¡œì„œ ì ì ˆí•œ ì–´ì¡°ì™€ ìŠ¤íƒ€ì¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.
2. TRPGì˜ ì¼ë°˜ì ì¸ ì§€ì‹ê³¼ ì°½ì˜ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
3. ë‹µë³€ì€ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì œê³µí•˜ê³ , í•„ìš”í•œ ê²½ìš° í”Œë ˆì´ì–´ê°€ ì·¨í•  ìˆ˜ ìˆëŠ” ë‹¤ìŒ í–‰ë™ì„ ì œì•ˆí•˜ì„¸ìš”.
4. ìºë¦­í„° ì •ë³´ê°€ ì œê³µë˜ì—ˆë‹¤ë©´ ìºë¦­í„°ì˜ íŠ¹ì„±ê³¼ ëŠ¥ë ¥ì„ ê³ ë ¤í•˜ì—¬ ì‘ë‹µí•˜ì„¸ìš”.
5. ì‚¬ìš©ìê°€ 'ëœë¤ ìºë¦­í„°' ë˜ëŠ” 'ë¬´ì‘ìœ„ ìºë¦­í„°'ë¥¼ ìš”ì²­í•˜ëŠ” ê²½ìš° ì°½ì˜ì ìœ¼ë¡œ ìºë¦­í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
6. ìƒí™©ì— ë§ëŠ” í¥ë¯¸ë¡œìš´ ìŠ¤í† ë¦¬í…”ë§ê³¼ ëª°ì…ê° ìˆëŠ” ì„¤ëª…ì„ ì œê³µí•˜ì„¸ìš”.

## ì‘ë‹µ:
"""
        
        # ì‘ë‹µ ìƒì„± (ë†’ì€ temperatureë¡œ ì°½ì˜ì ì¸ ì‘ë‹µ ìƒì„±)
        model = genai.GenerativeModel(GENERATION_MODEL)
        generation_config = genai.types.GenerationConfig(
            temperature=LLM_TEMPERATURE,      # ì°½ì˜ì„± ìˆ˜ì¤€
            top_p=LLM_TOP_P,                  # í† í° ì„ íƒ ë‹¤ì–‘ì„±
            top_k=LLM_TOP_K,                  # í›„ë³´ í† í° ìˆ˜
            max_output_tokens=LLM_MAX_TOKENS, # ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜
        )
        response = model.generate_content(prompt, generation_config=generation_config)
        
        # ğŸš¨ CRITICAL FIX: LLM ì‘ë‹µ ì•ˆì „ì„± ê²€ì‚¬
        if response.candidates and len(response.candidates) > 0:
            candidate = response.candidates[0]
            
            # finish_reason í™•ì¸
            if hasattr(candidate, 'finish_reason') and candidate.finish_reason != 1:  # 1 = STOP (ì •ìƒ ì™„ë£Œ)
                print(f"âš ï¸ LLM ì‘ë‹µ finish_reason: {candidate.finish_reason}")
                
                if candidate.finish_reason == 2:  # MAX_TOKENS
                    return "ì‘ë‹µì´ ë„ˆë¬´ ê¸¸ì–´ì„œ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë” ê°„ë‹¨í•œ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."
                elif candidate.finish_reason == 3:  # SAFETY
                    return "ì•ˆì „ ì •ì±…ì— ì˜í•´ ì‘ë‹µì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
                elif candidate.finish_reason == 4:  # RECITATION
                    return "ì €ì‘ê¶Œ ë¬¸ì œë¡œ ì‘ë‹µì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
                else:
                    return "ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            
            # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if hasattr(candidate, 'content') and candidate.content.parts:
                return candidate.content.parts[0].text
            else:
                return response.text  # í´ë°±
        else:
            return "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            
    except Exception as e:
        print(f"LLM ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(traceback.format_exc())
        return "ì£„ì†¡í•©ë‹ˆë‹¤, ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

# generate_answer_with_rag í•¨ìˆ˜ëŠ” ë³€ê²½ ì—†ìŒ (LLM í˜¸ì¶œ ë¡œì§ ë™ì¼)
def generate_answer_with_rag(query, similar_chunks, session_type="ê¸°íƒ€", character_context=""):
    """ìœ ì‚¬í•œ ì²­í¬ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ RAGë¡œ ë‹µë³€ ìƒì„±"""
    try:
        # ë¬¸ë§¥ êµ¬ì„±
        context = ""
        for i, (score, text) in enumerate(similar_chunks, 1):
            context += f"--- ì²­í¬ {i} (ê´€ë ¨ë„: {score:.3f}) ---\n{text}\n\n"
        
        # ì„¸ì…˜ ìœ í˜•ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì¡°ì •
        session_guidance = ""
        if session_type == "ìºë¦­í„°_ìƒì„±":
            session_guidance = """
ë‹¹ì‹ ì€ ì§€ê¸ˆ ìºë¦­í„° ìƒì„± ì„¸ì…˜ì— ìˆìŠµë‹ˆë‹¤. í”Œë ˆì´ì–´ê°€ ìºë¦­í„°ë¥¼ ë§Œë“œëŠ” ê²ƒì„ ë•ê³  ìˆìœ¼ë‹ˆ, 
ìºë¦­í„° ìƒì„±ì— í•„ìš”í•œ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”. ë§Œì•½ í”Œë ˆì´ì–´ê°€ ëœë¤ ìºë¦­í„°ë‚˜ ë¬´ì‘ìœ„ ìºë¦­í„°ë¥¼ ë§Œë“¤ì–´ë‹¬ë¼ê³  í•˜ë©´, 
ìºë¦­í„°ê°€ ìƒì„±ë  ê²ƒì´ë¼ê³  ì•ˆë‚´í•´ ì£¼ì„¸ìš”.
"""
        elif session_type == "ì‹œë‚˜ë¦¬ì˜¤_ìƒì„±":
            session_guidance = """
ë‹¹ì‹ ì€ ì§€ê¸ˆ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì„¸ì…˜ì— ìˆìŠµë‹ˆë‹¤. í¥ë¯¸ë¡œìš´ ëª¨í—˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“¤ê³  ìˆìœ¼ë‹ˆ,
í”Œë ˆì´ì–´ì˜ ì§ˆë¬¸ì— ë§ê²Œ ì´ì•¼ê¸°, ì¥ì†Œ, ë¹„ë°€, ë³´ë¬¼, NPC ë“±ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
"""
        elif session_type == "ëª¨í—˜_ì§„í–‰" or session_type == "ë˜ì „_íƒí—˜":
            session_guidance = """
ë‹¹ì‹ ì€ ì§€ê¸ˆ ëª¨í—˜/ë˜ì „ íƒí—˜ ì„¸ì…˜ì— ìˆìŠµë‹ˆë‹¤. ê²Œì„ë§ˆìŠ¤í„°ë¡œì„œ í”Œë ˆì´ì–´ì˜ í–‰ë™ì— ë°˜ì‘í•˜ê³ ,
ì£¼ë³€ í™˜ê²½ê³¼ ìƒí™©ì— ëŒ€í•œ ìƒìƒí•œ ì„¤ëª…ì„ ì œê³µí•˜ì„¸ìš”. ë„ì „ê³¼ ìœ„í—˜ì„ ê´€ë¦¬í•˜ê³  í”Œë ˆì´ì–´ê°€ ì„ íƒí•  ìˆ˜ ìˆëŠ” ì˜µì…˜ì„ ì œì‹œí•˜ì„¸ìš”.
"""
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ê¸°ë°˜ TRPG(í…Œì´ë¸”í†± ë¡¤í”Œë ˆì‰ ê²Œì„)ì˜ ê²Œì„ë§ˆìŠ¤í„°ì…ë‹ˆë‹¤. 

## ì„¸ì…˜ ì •ë³´
í˜„ì¬ ì„¸ì…˜: {session_type}
{session_guidance}

## ìºë¦­í„° ì •ë³´
{character_context}

## ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ê²°ê³¼
{context}

## ì‚¬ìš©ì ì§ˆë¬¸
"{query}"

## ì§€ì¹¨
1. ê²Œì„ë§ˆìŠ¤í„°ë¡œì„œ ì ì ˆí•œ ì–´ì¡°ì™€ ìŠ¤íƒ€ì¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.
2. ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ê²°ê³¼ ë‚´ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•„ ë‹µë³€ì— í™œìš©í•˜ì„¸ìš”.
3. ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ëŠ” ì •ë³´ëŠ” TRPG ë§¥ë½ì— ë§ê²Œ ì°½ì˜ì ìœ¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.
4. ë‹µë³€ì€ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì œê³µí•˜ê³ , í•„ìš”í•œ ê²½ìš° í”Œë ˆì´ì–´ê°€ ì·¨í•  ìˆ˜ ìˆëŠ” ë‹¤ìŒ í–‰ë™ì„ ì œì•ˆí•˜ì„¸ìš”.
5. ìºë¦­í„° ì •ë³´ê°€ ì œê³µë˜ì—ˆë‹¤ë©´ ìºë¦­í„°ì˜ íŠ¹ì„±ê³¼ ëŠ¥ë ¥ì„ ê³ ë ¤í•˜ì—¬ ì‘ë‹µí•˜ì„¸ìš”.
6. ì‚¬ìš©ìê°€ 'ëœë¤ ìºë¦­í„°' ë˜ëŠ” 'ë¬´ì‘ìœ„ ìºë¦­í„°'ë¥¼ ìš”ì²­í•˜ëŠ” ê²½ìš° ìºë¦­í„°ê°€ ìƒì„±ë  ê²ƒì´ë¼ê³  ì•ˆë‚´í•´ì£¼ì„¸ìš”.

## ì‘ë‹µ:
"""
        
        # ì‘ë‹µ ìƒì„± (ë†’ì€ temperatureë¡œ ì°½ì˜ì ì¸ ì‘ë‹µ ìƒì„±)
        model = genai.GenerativeModel(GENERATION_MODEL)
        generation_config = genai.types.GenerationConfig(
            temperature=LLM_TEMPERATURE,      # ì°½ì˜ì„± ìˆ˜ì¤€
            top_p=LLM_TOP_P,                  # í† í° ì„ íƒ ë‹¤ì–‘ì„±
            top_k=LLM_TOP_K,                  # í›„ë³´ í† í° ìˆ˜
            max_output_tokens=LLM_MAX_TOKENS, # ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜
        )
        response = model.generate_content(prompt, generation_config=generation_config)
        
        # ğŸš¨ CRITICAL FIX: LLM ì‘ë‹µ ì•ˆì „ì„± ê²€ì‚¬
        if response.candidates and len(response.candidates) > 0:
            candidate = response.candidates[0]
            
            # finish_reason í™•ì¸
            if hasattr(candidate, 'finish_reason') and candidate.finish_reason != 1:  # 1 = STOP (ì •ìƒ ì™„ë£Œ)
                print(f"âš ï¸ RAG LLM ì‘ë‹µ finish_reason: {candidate.finish_reason}")
                
                if candidate.finish_reason == 2:  # MAX_TOKENS
                    return "ì‘ë‹µì´ ë„ˆë¬´ ê¸¸ì–´ì„œ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë” ê°„ë‹¨í•œ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."
                elif candidate.finish_reason == 3:  # SAFETY
                    return "ì•ˆì „ ì •ì±…ì— ì˜í•´ ì‘ë‹µì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
                elif candidate.finish_reason == 4:  # RECITATION
                    return "ì €ì‘ê¶Œ ë¬¸ì œë¡œ ì‘ë‹µì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
                else:
                    return "ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            
            # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if hasattr(candidate, 'content') and candidate.content.parts:
                return candidate.content.parts[0].text
            else:
                return response.text  # í´ë°±
        else:
            return "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            
    except Exception as e:
        print(f"RAG ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(traceback.format_exc())
        return "ì£„ì†¡í•©ë‹ˆë‹¤, ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

# --- ì‹¤í–‰ íë¦„ ---
if __name__ == "__main__":
    # 1. ì²˜ë¦¬í•  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ ì§€ì •
    md_file_path = "ìš¸íƒ€ë¦¬ ë„ˆë¨¸ - ë˜ ë‹¤ë¥¸ ëª¨í—˜ìœ¼ë¡œ RAG ì†ŒìŠ¤ ë°ì´í„°.md" # ì—¬ê¸°ì— ì‹¤ì œ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.

    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(md_file_path):
        print(f"ì˜¤ë¥˜: ë§ˆí¬ë‹¤ìš´ íŒŒì¼ '{md_file_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # --- ë°ì´í„° ì¤€ë¹„ (ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬ ë° Supabase ì €ì¥) ---
        # ì´ ë¶€ë¶„ì€ íŒŒì¼ ë‚´ìš©ì´ ë³€ê²½ë  ë•Œë§Œ ì‹¤í–‰í•˜ê±°ë‚˜,
        # ì´ë¯¸ ë°ì´í„°ê°€ ì €ì¥ë˜ì–´ ìˆë‹¤ë©´ ì£¼ì„ ì²˜ë¦¬í•˜ê³  ê²€ìƒ‰/ë‹µë³€ ë¶€ë¶„ë§Œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

        print("\n=== ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬ ë° ì„ë² ë”© ì €ì¥ ì‹œì‘ ===")
        # ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ ì½ê¸°
        md_text = read_markdown_file(md_file_path)

        if md_text:
            # í…ìŠ¤íŠ¸ ë¶„í• 
            text_chunks = split_text(md_text)

            if text_chunks:
                # Supabaseì— ì²­í¬ ë° ì„ë² ë”© ì €ì¥
                # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì‹œë„
                print(f"ê¸°ì¡´ '{TABLE_NAME}' í…Œì´ë¸” ë°ì´í„° ì‚­ì œ ì¤‘...")
                try:
                    supabase.table(TABLE_NAME).delete().neq('id', 0).execute() # ëª¨ë“  ë°ì´í„° ì‚­ì œ
                    print("ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ.")
                except Exception as e:
                    print(f"ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}, ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
                
                store_chunks_in_supabase(text_chunks)
            else:
                print("í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            print("ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print("=== ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬ ë° ì„ë² ë”© ì €ì¥ ì™„ë£Œ ===\n")


        # --- RAG ì‹¤í–‰ (ì§ˆë¬¸ -> ê²€ìƒ‰ -> ë‹µë³€ ìƒì„±) ---
        print("\n=== RAG ì§ˆë¬¸ ì‘ë‹µ ì‹œì‘ ===")
        # ì‚¬ìš©ì ì§ˆë¬¸ ì˜ˆì‹œ
        user_question = "ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš© ìš”ì•½í•´ì¤˜." # ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.

        # 1. ìœ ì‚¬ì„± ê²€ìƒ‰ (ì„ê³„ê°’ ë‚®ì¶¤)
        similar_chunks = find_similar_chunks(user_question, match_count=3, match_threshold=0.5)

        # 2. ë‹µë³€ ìƒì„±
        final_answer = generate_answer_with_rag(user_question, similar_chunks, "ìºë¦­í„°_ìƒì„±")

        # 3. ìµœì¢… ë‹µë³€ ì¶œë ¥
        print("\n--- ìµœì¢… ë‹µë³€ ---")
        print(final_answer)
        print("=================\n")